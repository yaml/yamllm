#!/usr/bin/env ys-0


#------------------------------------------------------------------------------
# Initialization and sanity checks
#------------------------------------------------------------------------------

ys-min-version =: 63

when-not ENV.YAMLLM_ROOT:
  die: "YAMLLM_ROOT not set. Try: 'source bashrc'."

when (ys-min-version > VERSION.split(/\./).last().num()):
  die: "ys version 0.1.$ys-min-version or greater required"

log-dir =:
  log-dir =: ENV.YAMLLM_LOG_DIR
  when ENV.YAMLLM_LOG_DIR:
    if log-dir.fs-d():
      then: log-dir
      else:
        warn: "NOTE: YAMLLM_LOG_DIR=$log-dir but no such directory."

shortcuts =::
  llama3: llama3-70b-8192
  llama38b: llama3-8b-8192
  gemma: gemma-7b-it
  gemma2: gemma2-9b-it
  mixtral: mixtral-8x7b-32768
  whisper: whisper-large-v3
  gpt4o: gpt-4o
  gpt4o-: gpt-4o-mini
  gpt4t: gpt-4-turbo
  gpt4: gpt-4
  gpt3: gpt-3.5-turbo
  dalle2: dall-e-2
  dalle3: dall-e-3

when (ENV.YAMLLM_MODEL = 'list'):
  say: shortcuts.yaml/dump()
  exit: 0

api-model =:
  cond:
    ENV.YAMLLM_MODEL: ENV.YAMLLM_MODEL
    ENV.YAMLLM_GROQ_API_KEY: 'llama3'
    ENV.YAMLLM_OPENAI_API_KEY: 'gpt4++'
    =>: die("Can't determine model, no API key set.")

api-model =: shortcuts.get(api-model) || api-model

groq-models =::
- llama3-70b-8192
- llama3-8b-8192
- gemma-7b-it
- gemma2-9b-it
- mixtral-8x7b-32768
- whisper-large-v3

openai-models =::
- gpt-4o
- gpt-4o-mini
- gpt-4-turbo
- gpt-4
- gpt-3.5-turbo
- dall-e-2
- dall-e-3

or:
  api-model.in(groq-models)
  api-model.in(openai-models)
  die("Unrecognized LLM model '$api-model':\n\n" +
      yaml/dump(shortcuts))

env-vars =::
  YAMLLM_API_SLEEP: 1
  YAMLLM_DEBUG: 1
  YAMLLM_GROQ_API_KEY: 1
  YAMLLM_GROQ_API_URL: 1
  YAMLLM_LOG_DIR: 1
  YAMLLM_MODEL: 1
  YAMLLM_OPENAI_API_KEY: 1
  YAMLLM_OPENAI_API_URL: 1
  YAMLLM_POST: 1
  YAMLLM_PRE: 1
  YAMLLM_PROMPT: 1
  YAMLLM_ROOT: 1
  YAMLLM_SIZE: 1
  YAMLLM_TEMP: 1
  YAMLLM_TEST_DEBUG: 1
  YAMLLM_TEST_FILE: 1
  YAMLLM_TOPP: 1

each [k ENV.keys()]:
  when ((k =~ /^YAMLLM_/) && not(env-vars.get(k))):
    die: |
      Invalid env var '$k'.
      Not one of:
      $(env-vars.keys().join("\n"))


#------------------------------------------------------------------------------
# Main script logic
#------------------------------------------------------------------------------
defn main(prompt=nil):
  when prompt.in(['--help' '-h']): usage()

  prompt =: get-prompt(prompt)

  if prompt:
    then:
      say: "Q: $prompt"
      run: prompt
    else:
      say: "(Use ctl-d or 'exit' to quit)"
      while true:
        run: ask-for-prompt()

defn usage():
  file =: FILE.replace(rx('.*/(.*)') "$1")
  say: |
    $ $file           - Ask for prompt
    $ $file <prompt>  - Specific prompt
  exit: 0

defn run(prompt):
  when prompt.in(['exit' 'quit' 'q' 'Q']): exit()

  orig-prompt =: prompt

  prompt =: |
    $get-preamble()
    prompt:
    ````
    $prompt
    ````
    $get-postamble()

  print: "$api-model: "
  answer =:
    cond:
      api-model =~ /^dall-e/: openai-image(prompt).data.0.url
      api-model.in(groq-models): groq(prompt).message().format()
      api-model.in(openai-models): openai-chat(prompt).message().format()
      =>: die()

  when log-dir:
    spit log-file(orig-prompt): |
      `````
      $(prompt.trim())
      `````
      ---------------------------------------------------------------------------
      $answer

  say: answer

defn log-file(prompt):
  stamp =: sh("date +%Y%m%d-%H%M%S").out.chomp()
  prompt .=: replace(/[^\w]/ '-')
             .replace(/--+/ '-')
             .replace(/-+$/ '')
  prompt .=: subs(0 min(count(prompt) 20))
             .str/lower-case()
  prompt =:
    if empty?(prompt):
      +'unknown'
      prompt

  =>: "$log-dir/${stamp}-$api-model+$prompt.md"


#------------------------------------------------------------------------------
# Groq API functions
#------------------------------------------------------------------------------
defn groq(prompt):
  api-url =: ENV.YAMLLM_GROQ_API_URL ||
    'https://api.groq.com/openai/v1/chat/completions'

  api-key =: ENV.YAMLLM_GROQ_API_KEY ||
    die("\nPlease 'export YAMLLM_GROQ_API_KEY=<your-groq-api-key'
        \nGet one here:\ https://console.groq.com/keys")

  request =::
    :headers:
      :Content-Type: application/json
      :Authorization:: "Bearer $api-key"
    :body::
      json/dump::
        :model:: api-model
        :messages:
        - :role: user
          :content:: prompt
        :temperature:: (ENV.YAMLLM_TEMP || 0.8).num()
        ! keyword('top_p'):: (ENV.YAMLLM_TOPP || 1.0).num()

  when ENV.YAMLLM_DEBUG:
    say: request.yaml/dump()

  response =:
    try:
      http/post api-url: request
      catch e:
        e =: ex-data(e)
        say:
          yaml/dump::
            status:: e.status
            body:: e.body.json/load()
            api-key:: api-key
        exit: 1

  when ENV.YAMLLM_DEBUG:
    say: response.yaml/dump()

  when (response.status != 200):
    die(response)

  json/load: response.body

defn message(response):
  =>: response.choices.0.message.content


#------------------------------------------------------------------------------
# OpenAI API functions
#------------------------------------------------------------------------------
defn openai-chat(prompt):
  api-url =: ENV.YAMLLM_OPENAI_API_URL ||
    'https://api.openai.com/v1/chat/completions'

  api-key =: ENV.YAMLLM_OPENAI_API_KEY ||
    die("\nPlease 'export YAMLLM_OPENAI_API_KEY=<your-groq-api-key'
        \nGet one here:\ https://platform.openai.com/api-keys")

  request =::
    :headers:
      :Content-Type: application/json
      :Authorization:: "Bearer $api-key"
    :body::
      json/dump::
        :model:: api-model
        :messages:
        - :role: user
          :content:: prompt
        :temperature:: (ENV.YAMLLM_TEMP || 0.8).num()

  when ENV.YAMLLM_DEBUG:
    say: request.yaml/dump()

  response =:
    try:
      http/post api-url: request
      catch e:
        e =: ex-data(e)
        say:
          yaml/dump::
            status:: e.status
            body:: e.body.json/load()
            api-key:: api-key
        exit: 1

  when ENV.YAMLLM_DEBUG:
    say: response.yaml/dump()

  when (response.status != 200):
    die(response)

  json/load: response.body

defn openai-image(prompt):
  api-url =: ENV.YAMLLM_OPENAI_API_URL ||
    'https://api.openai.com/v1/images/generations'

  api-key =: ENV.YAMLLM_OPENAI_API_KEY ||
    die("\nPlease 'export YAMLLM_OPENAI_API_KEY=<your-groq-api-key'
        \nGet one here:\ https://platform.openai.com/api-keys")

  request =::
    :headers:
      :Content-Type: application/json
      :Authorization:: "Bearer $api-key"
    :body::
      json/dump::
        :model:: api-model
        :prompt:: prompt
        :n: 1
        :size:: ENV.YAMLLM_SIZE || '1024x1024'

  when ENV.YAMLLM_DEBUG:
    say: request.yaml/dump()

  response =:
    try:
      http/post api-url: request
      catch e:
        e =: ex-data(e)
        say:
          yaml/dump::
            status:: e.status
            body:: e.body.json/load()
            api-key:: api-key
        exit: 1

  when ENV.YAMLLM_DEBUG:
    say: response.yaml/dump()

  when (response.status != 200):
    die(response)

  json/load: response.body


#------------------------------------------------------------------------------
# Helper functions
#------------------------------------------------------------------------------
defn get-prompt(prompt):
  env =: ENV.YAMLLM_PROMPT
  if prompt:
    if env:
      then: die("Can't specify prompt string when using YAMLLM_PROMPT var.")
      else: prompt
    if env:
      then: env.slurp()
      else: nil

defn ask-for-prompt():
  loop:
    print: "Q: "
    q =: read-line()
    # ctl-d returns nil to exit:
    when q.nil?(): exit()
    if q.empty?(): recur() q

defn get-preamble():
  when-let [file ENV.YAMLLM_PRE]: slurp(file)

defn get-postamble():
  when-let [file ENV.YAMLLM_POST]: slurp(file)

defn format(string):
  string .=: triml().prettier().trimr()

  if (string =~ /\n/):
    +"\n$string"
    string

defn prettier(s):
  if sh('which prettier').out.empty?():
    then: s
    else:
      cmd =:: prettier --stdin-filepath=x.md
                       --print-width=80
                       --prose-wrap=always
      =>: sh(cmd {:in s}).out

# vim: sw=2 ft=yaml lisp:
