#!/usr/bin/env ys-0


#------------------------------------------------------------------------------
# Initialization and sanity checks
#------------------------------------------------------------------------------

ys-min-version =: 80

when ys-min-version > VERSION.split(/\./):last:N:
  die: "ys version 0.1.$ys-min-version or greater required"

config-file =: "$(ENV.HOME)/.yamllm/config.yaml"
config =:
  cond:
    ENV.YAMLLM_CONFIG: ENV.YAMLLM_CONFIG:slurp:yaml/load
    config-file:fs-e: config-file:slurp:yaml/load
    else: die("No '$config-file' or YAMLLM_CONFIG")

session-dir =:
  ENV.YAMLLM_SESSION_DIR ||
  config.session-dir ||
  '.'

session-file =:
  atom:
    when+ ENV.YAMLLM_SESSION:
      if _.starts?('/'):
        _
        "$session-dir/$(_)"

shortcuts =::
  dalle2: dall-e-2
  dalle3: dall-e-3
  gemma2: gemma2-9b-it
  gemma: gemma-7b-it
  gpt3: gpt-3.5-turbo
  gpt4: gpt-4
  gpt4o: gpt-4o
  gpt4o-: gpt-4o-mini
  gpt4t: gpt-4-turbo
  haiku: claude-3-5-haiku-latest
  llama38b: llama3-8b-8192
  llama3: llama3-70b-8192
  mixtral: mixtral-8x7b-32768
  opus: claude-3-opus-latest
  sonnet: claude-3-5-sonnet-latest
  whisper: whisper-large-v3

when ENV.YAMLLM_MODEL == 'list':
  say: shortcuts:yaml/dump
  exit: 0

api-model =:
  cond:
    ENV.YAMLLM_MODEL: ENV.YAMLLM_MODEL
    config.default-model: config.default-model
    else: die("Can't determine model, no API key set.")

api-model =: shortcuts.$api-model || api-model

anthropic-models =::
- claude-3-5-haiku-latest
- claude-3-5-sonnet-latest
- claude-3-opus-latest

groq-models =::
- llama3-70b-8192
- llama3-8b-8192
- gemma-7b-it
- gemma2-9b-it
- mixtral-8x7b-32768
- whisper-large-v3

openai-models =::
- gpt-4o
- gpt-4o-mini
- gpt-4-turbo
- gpt-4
- gpt-3.5-turbo
- dall-e-2
- dall-e-3

or:
  api-model.in?(anthropic-models)
  api-model.in?(groq-models)
  api-model.in?(openai-models)
  die("Unrecognized LLM model '$api-model':\n\n" +
  yaml/dump(shortcuts))

env-vars =::
  YAMLLM_API_SLEEP: 1
  YAMLLM_CONFIG: 1
  YAMLLM_DEBUG: 1
  YAMLLM_IMAGE_SIZE: 1
  YAMLLM_MODEL: 1
  YAMLLM_POST: 1
  YAMLLM_PRE: 1
  YAMLLM_PROMPT: 1
  YAMLLM_ROOT: 1
  YAMLLM_SESSION: 1
  YAMLLM_TEMP: 1
  YAMLLM_TEST_DEBUG: 1
  YAMLLM_TEST_FILE: 1
  YAMLLM_TOPP: 1

each [k ENV:keys]:
  when (k =~ /^YAMLLM_/) && not(env-vars.get(k)):
    die: |
      Invalid env var '$k'.
      Not one of:
      $(env-vars:keys.join("\n"))


#------------------------------------------------------------------------------
# Main script logic
#------------------------------------------------------------------------------
defn main(prompt=nil):
  when prompt.in?(['--help' '-h']): usage()

  prompt-orig =: prompt
  prompt =: get-prompt(prompt)

  if prompt:
    then:
      say: "Q: $prompt-orig"
      run: prompt
    else:
      say: "(Use ctl-d or 'exit' to quit)"
      while true:
        run: ask-for-prompt()

defn usage():
  file =: FILE.replace(qr('.*/(.*)') "$1")
  say: |
    $ $file           - Ask for prompt
    $ $file <prompt>  - Specific prompt
  exit: 0

defn run(prompt session=nil):
  session =: session-file:D || session

  when prompt.in?(['exit' 'quit' 'q' 'Q']): exit()

  orig-prompt =: prompt

  session-text =:
    when session && session:fs-e:
      session:slurp

  prompt =: |
    $get-preamble()
    $session-text
    $prompt
    $get-postamble()

  print: "$api-model: "
  answer =:
    cond:
      api-model =~ /^dall-e/:
        openai-image(prompt).data.0.url
      api-model.in?(anthropic-models):
        anthropic(prompt):anthropic-message:format
      api-model.in?(groq-models):
        groq(prompt).choices.0.message.content:format
      api-model.in?(openai-models):
        openai-chat(prompt).choices.0.message.content:format
      else: die()

  say: answer

  when session:
    spit session _ :append true: |+
      Q: $(orig-prompt:trim)
      A: $(answer:trim)

defn get-session-file(prompt):
  stamp =: sh("date +%Y%m%d-%H%M%S").out:chomp
  prompt .=: replace(/[^\w]/ '-')
    .replace(/--+/ '-')
    .replace(/-+$/ '')
  prompt .=: subs(0 min(prompt.# 20)):lc
  prompt |||=: 'unknown'

  =>: "$session-dir/$stamp-$api-model+$prompt.txt"


#------------------------------------------------------------------------------
# Anthropic API functions
#------------------------------------------------------------------------------
defn anthropic(prompt):
  api-url =: 'https://api.anthropic.com/v1/messages'

  api-key =: config.api-key.anthropic ||
    die("\nAPI key not in 'config.api-key.anthropic'.
    \nGet one here:\ https://console.anthropic.com/settings/keys")

  request =::
    :headers:
      :x-api-key:: api-key
      :anthropic-version: 2023-06-01
      :content-type: application/json
    :body::
      json/dump::
        :model:: api-model
        max_tokens: 1024
        :messages:
        - :role: user
          :content:: prompt

  when ENV.YAMLLM_DEBUG:
    say: request:yaml/dump

  response =:
    try:
      http/post api-url: request
      catch e:
        e =: ex-data(e)
        say:
          yaml/dump::
            status:: e.status
            body:: e.body:json/load
            api-key:: api-key
        exit: 1

  when ENV.YAMLLM_DEBUG:
    say: response:yaml/dump

  when response.status != 200:
    die(response)

  json/load: response.body

defn anthropic-message(response):
  =>: response.content.0.text


#------------------------------------------------------------------------------
# Groq API functions
#------------------------------------------------------------------------------
defn groq(prompt):
  api-url =: 'https://api.groq.com/openai/v1/chat/completions'

  api-key =: config.api-key.groq ||
    die("\nAPI key not in 'config.api-key.groq'.
    \nGet one here:\ https://console.groq.com/keys")

  request =::
    :headers:
      :Content-Type: application/json
      :Authorization:: "Bearer $api-key"
    :body::
      json/dump::
        :model:: api-model
        :messages:
        - :role: user
          :content:: prompt
        :temperature:: (ENV.YAMLLM_TEMP || 0.8):N
        ! keyword('top_p'):: (ENV.YAMLLM_TOPP || 1.0):N

  when ENV.YAMLLM_DEBUG:
    say: request:yaml/dump

  response =:
    try:
      http/post api-url: request
      catch e:
        e =: ex-data(e)
        say:
          yaml/dump::
            status:: e.status
            body:: e.body:json/load
            api-key:: api-key
        exit: 1

  when ENV.YAMLLM_DEBUG:
    say: response:yaml/dump

  when response.status != 200:
    die(response)

  json/load: response.body

defn message(response):
  =>: response


#------------------------------------------------------------------------------
# OpenAI API functions
#------------------------------------------------------------------------------
defn openai-chat(prompt):
  api-url =: 'https://api.openai.com/v1/chat/completions'

  api-key =: config.api-key.openai ||
    die("\nAPI key not in 'config.api-key.openai'.
    \nGet one here:\ https://platform.openai.com/api-keys")

  request =::
    :headers:
      :Content-Type: application/json
      :Authorization:: "Bearer $api-key"
    :body::
      json/dump::
        :model:: api-model
        :messages:
        - :role: user
          :content:: prompt
          :temperature:: (ENV.YAMLLM_TEMP || 0.8):N

  when ENV.YAMLLM_DEBUG:
    say: request:yaml/dump

  response =:
    try:
      http/post api-url: request
      catch e:
        e =: ex-data(e)
        say:
          yaml/dump::
            status:: e.status
            body:: e.body:json/load
            api-key:: api-key
        exit: 1

  when ENV.YAMLLM_DEBUG:
    say: response:yaml/dump

  when response.status != 200:
    die(response)

  json/load: response.body

defn openai-image(prompt):
  api-url =: 'https://api.openai.com/v1/images/generations'

  api-key =: config.api-key.openai ||
    die("\nAPI key not in 'config.api-key.openai'.
    \nGet one here:\ https://platform.openai.com/api-keys")

  request =::
    :headers:
      :Content-Type: application/json
      :Authorization:: "Bearer $api-key"
    :body::
      json/dump::
        :model:: api-model
        :prompt:: prompt
        :n: 1
        :size:: ENV.YAMLLM_IMAGE_SIZE || '1024x1024'

  when ENV.YAMLLM_DEBUG:
    say: request:yaml/dump

  response =:
    try:
      http/post api-url: request
      catch e:
        e =: ex-data(e)
        say:
          yaml/dump::
            status:: e.status
            body:: e.body:json/load
            api-key:: api-key
        exit: 1

  when ENV.YAMLLM_DEBUG:
    say: response:yaml/dump

  when response.status != 200:
    die(response)

  json/load: response.body


#------------------------------------------------------------------------------
# Helper functions
#------------------------------------------------------------------------------
defn get-prompt(prompt):
  env =: ENV.YAMLLM_PROMPT
  if prompt:
    if env:
      then: die("Can't specify prompt string when using YAMLLM_PROMPT var.")
      else: prompt:expand-file-paths
    if env:
      then: env:slurp
      else: nil

defn expand-file-paths(prompt):
  replace prompt /%%%(\S+)%%%\s*/:
    fn(m):
      if m.1:fs-e:
        then: "\n```\n$(m.1:slurp:chomp)\n```\n"
        else: m.0

defn ask-for-prompt():
  loop:
    print: "Q: "
    q =: read-line()
    # ctl-d returns nil to exit:
    q =:
      if q:
        q:expand-file-paths
        exit()
    when q.? && not(session-file:deref):
      reset! session-file: get-session-file(q)
    if q:empty?:
      recur:
      else: q

defn get-preamble():
  when-let file ENV.YAMLLM_PRE: slurp(file)

defn get-postamble():
  when-let file ENV.YAMLLM_POST: slurp(file)

defn format(string):
  string =: string:triml:prettier:trimr

  if string =~ /\n/:
    +"\n$string"
    string

defn prettier(s):
  if sh('which prettier').out:empty?:
    then: s
    else:
      cmd =:: prettier --stdin-filepath=x.md
        --print-width=80
        --prose-wrap=always
      sh(cmd {:in s}): .out

# vim: sw=2 ft=yaml lisp:
